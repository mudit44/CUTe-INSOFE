dist(rbind(x,y))
mydata <- scale(mtcars)
#simple distance calculation between Honda Civic and Camaro
x <- mydata['Honda Civic',]
y <- mydata['Camaro Z28',]
dist(rbind(x,y))
rm(list=ls(all=TRUE))
#load mtcars data
data(mtcars)
str(mtcars)
mydata <- data.frame(mtcars[,1:7])
sum(is.na(mydata))
summary(mydata)
str(mydata)
#standardize variables
mydata <- scale(mtcars)
#simple distance calculation between Honda Civic and Camaro
x <- mydata['Honda Civic',]
y <- mydata['Camaro Z28',]
dist(rbind(x,y))
rm(list=ls(all=TRUE))
#load mtcars data
data(mtcars)
str(mtcars)
mydata <- data.frame(mtcars[,1:7])
sum(is.na(mydata))
summary(mydata)
str(mydata)
#standardize variables
mydata <- scale(mydata)
#simple distance calculation between Honda Civic and Camaro
x <- mydata['Honda Civic',]
y <- mydata['Camaro Z28',]
dist(rbind(x,y))
#distance matrix euclidean
d <- dist(mydata,method = 'euclidean')
view(as.matrix(d))
#distance matrix euclidean
d <- dist(mydata,method = 'euclidean')
View(as.matrix(d))
#display dendogram
plot(fit)
#distance matrix euclidean
d <- dist(mydata,method = 'euclidean')
View(as.matrix(d))
fit <- hclust(d,method='ward.D')
#display dendogram
plot(fit)
fit$merge
fit$dist.method
x <- c(1:3)
dx <- dist(x)
dx
hclust(dx,method='single')$height
install.packages('factoextra')
#Consider mtacrs data of R-datasets
data(mtcars)
str(mtcars)
mydata <- data.frame(mtcars[,1:7])
sum(is.na(mydata))
summary(mydata)
str(mydata)
mydata <- scale(mydata) # standardize variables
# simple distance calculation between HOnda Civic and Camaro Z28
x <-mydata["Honda Civic",]
y <- mydata["Camaro Z28",]
dist(rbind(x, y))
###-------------------------    Hierarchical Clustering     ------------------------###
# Ward's method
# distance matrix euclidean
d <- dist(mydata,method = "euclidean")
#View(data.matrix(d))
fit <- hclust(d, method="ward.D") #WARD is a min variance method to find compact clusters
plot(fit) # display dendogram
fit$merge
fit$dist.method
groups <- cutree(fit, k=5) # cut tree into 5 clusters
groups
# draw dendogram with red borders around the 5 clusters
rect.hclust(fit, k=5, border="red")
mydata_clusters=data.frame(mydata,groups)
par(mfrow=c(2,2))
fit1 <-hclust(d, method="complete")
fit2 <- hclust(d, method="single")
fit3 <- hclust(d, method='average')
fit4 <- hclust(d, method='Ward')
fit4 <- hclust(d, method='Ward.D')
fit4 <- hclust(d, method='ward.D')
############
dev.off()
par(mfrow = c(2, 2))
plot(fit3, leaflab = "textlike", main = "Average", xlab = "")
plot(fit, leaflab = "textlike", main = "Ward", xlab = "")
plot(fit2, leaflab = "textlike", main = "Single", xlab = "")
plot(fit1, leaflab = "textlike", main = "Complete", xlab = "")
#install.packages("factoextra")
library(factoextra)
fviz_cluster(fit, mydata)
fviz_cluster(fit, mydata)
rm(list=ls(all=TRUE))
install.packages('factoextra')
#Consider mtacrs data of R-datasets
data(mtcars)
str(mtcars)
mydata <- data.frame(mtcars[,1:7])
sum(is.na(mydata))
summary(mydata)
str(mydata)
mydata <- scale(mydata) # standardize variables
# simple distance calculation between HOnda Civic and Camaro Z28
x <-mydata["Honda Civic",]
y <- mydata["Camaro Z28",]
dist(rbind(x, y))
# # distance between Camaroz28 and Firebird
# z <- mydata["Pontiac Firebird",]
# dist(rbind(y, z))
# summary(mydata)
###-------------------------    Hierarchical Clustering     ------------------------###
# Ward's method
# distance matrix euclidean
d <- dist(mydata,method = "euclidean")
#View(data.matrix(d))
fit <- hclust(d, method="ward.D") #WARD is a min variance method to find compact clusters
plot(fit) # display dendogram
fit$merge
fit$dist.method
groups <- cutree(fit, k=5) # cut tree into 5 clusters
groups
#groups <- cutree(fit, k=2) # cut tree into 2 clusters
#groups
# draw dendogram with red borders around the 5 clusters
rect.hclust(fit, k=5, border="red")
mydata_clusters=data.frame(mydata,groups)
par(mfrow=c(2,2))
fit1 <-hclust(d, method="complete")
fit2 <- hclust(d, method="single")
fit3 <- hclust(d, method='average')
fit4 <- hclust(d, method='ward.D')
############
dev.off()
par(mfrow = c(2, 2))
plot(fit3, leaflab = "textlike", main = "Average", xlab = "")
plot(fit, leaflab = "textlike", main = "Ward", xlab = "")
plot(fit2, leaflab = "textlike", main = "Single", xlab = "")
plot(fit1, leaflab = "textlike", main = "Complete", xlab = "")
### Finding Optimum number of clusters
factoextra::fviz_nbclust(mydata[,-c(8)], hcut, method = "wss")
###-------------------------    K- means Clustering     ------------------------###
# K-Means Cluster Analysis with k = 5
set.seed(123)
fit <- kmeans(mydata, 5) # 5 cluster solution
fit$withinss
fit$betweenss
#study the mdoel
fit$cluster
fit$tot.withinss
fit
fit$centers
#or # get cluster means
#aggregate(mydata,
install.packages("factoextra")
fviz_cluster(fit, mydata)
# append cluster label to the actual data frame
mydata <- data.frame(mydata,
fit$cluster)
#write.csv(mydata,"kmeans_2.csv")
head(mydata)
### Finding Optimum number of clusters
# K-means:  Determine number of clusters by considering the withinness measure
wss <- 0
for (i in 1:15) {
wss[i] <- sum(kmeans(mydata,centers=i)$withinss)
}
#the scree plot
plot(1:15, wss,
type="b",
xlab="Number of Clusters",
ylab="Within groups sum of squares")
#Using factoextra library
factoextra::fviz_nbclust(mydata[,-c(8)], kmeans, method = "wss")
#k=6!?
set.seed(123)
final_fit_kmeans <- kmeans(mydata, 6) # 5 cluster solution
test_datapoint <- mtcars[sample(1:nrow(mtcars),1),]
closest.cluster <- function(x) {
cluster.dist <- apply(fit$centers, 1, function(y) sqrt(sum((x-y)^2)))
print(cluster.dist)
return(which.min(cluster.dist)[1])
}
closest.cluster(test_datapoint)
rm(list=ls(all=TRUE))
setwd("C:/Users/Mudit/Desktop/INSOFE/CUTe2_Group_Activity/20180415_Batch_40_CSE_7302c_CUTe")
#read the data
data <- read.csv('Data_20180408.csv',header = TRUE,na.strings = c(-99,NA,"NA","NA "," NA"))
#EDA(Explorative Data Analysis)
str(data)
summary(data)
dim(data)
#step 1 - check for NA's in the dataset.
sum(is.na(data))
#step 2 - check for NA's in target field. (here 0)
sum(is.na(data$Target))
#step 3 - check for NA's in all the columns, count them up.
sapply(data, function(x) sum(is.na(x)))
#step 4 - check for unique values/levels in the columns for checking whether a
#field is numerical or categorical.
sapply(data, function(x) range(x))
#step 5 - convert variables to factors.
data$A11 <- as.factor(data$A11)
data$A13 <- as.factor(data$A13)
data$A17 <- as.factor(data$A17)
data$A18 <- as.factor(data$A18)
data$A19 <- as.factor(data$A19)
data$A20 <- as.factor(data$A20)
data$A22 <- as.factor(data$A22)
data$Target <- as.factor(data$Target)
#step 6 - binning the data.
summary(data)
library(infotheo)
bin_freq <- discretize(data$A21,disc = "equalfreq",nbins = 4)
table(bin_freq)
tapply(data$A21,bin_freq,min)
tapply(data$A21,bin_freq,max)
bin_wid <- discretize(data$A21,disc = "equalwidth",nbins = 4)
table(bin_wid)
tapply(data$A21,bin_wid,min)z
tapply(data$A21,bin_wid,max)
#EDA(Explorative Data Analysis)
str(data)
#EDA(Explorative Data Analysis)
str(data)
#step 1 - check for NA's in the dataset.
sum(is.na(data))
#step 1 - check for NA's in the dataset.
sum(is.na(data))
#step 3 - check for NA's in all the columns, count them up.
sapply(data, function(x) sum(is.na(x)))
library(infotheo)
bin_freq <- discretize(data$A21,disc = "equalfreq",nbins = 4)
table(bin_freq)
tapply(data$A21,bin_freq,min)
tapply(data$A21,bin_freq,max)
bin_wid <- discretize(data$A21,disc = "equalwidth",nbins = 4)
table(bin_wid)
tapply(data$A21,bin_wid,min)z
tapply(data$A21,bin_wid,max)
library(infotheo)
bin_freq <- discretize(data$A21,disc = "equalfreq",nbins = 4)
table(bin_freq)
tapply(data$A21,bin_freq,min)
tapply(data$A21,bin_freq,max)
bin_wid <- discretize(data$A21,disc = "equalwidth",nbins = 4)
table(bin_wid)
tapply(data$A21,bin_wid,min)z
tapply(data$A21,bin_wid,max)
tapply(data$A21,bin_wid,max)
tapply(data$A21,bin_wid,min)z
bin_freq <- discretize(data$A21,disc = "equalfreq",nbins = 4)
table(bin_freq)
tapply(data$A21,bin_freq,min)
tapply(data$A21,bin_freq,max)
bin_wid <- discretize(data$A21,disc = "equalwidth",nbins = 4)
table(bin_wid)
tapply(data$A21,bin_wid,min)z
tapply(data$A21,bin_wid,max)
table(bin_wid)
#impute the data.
library(DMwR)
data <- centralImputation(data)
#cross checking.
sum(is.na(data))
#making ID equal to 0.
data$ID <- NULL
#split the data into train and test.
rows=seq(1,nrow(data),1)
set.seed(123)
trainRows=sample(rows,round((70*nrow(data))/100))
train = data[trainRows,]
test = data[-trainRows,]
View(train)
summary(train)
names(train)
# log_reg <- glm(Target~., data = train, family = binomial)
# Error in `contrasts<-`(`*tmp*`, value = contr.funs[1 + isOF[nn]]) :
# contrasts can be applied only to factors with 2 or more levels
# This type of error will be thrown in case of a variable which has only one value.
# Here A21, it has value of 27 as a whole, so we will be dropping it.
train$A11 <- NULL
test$A11 <- NULL
tr13 <- train$A13
tr18 <- train$A18
tr22 <- train$A22
te13 <- test$A13
te18 <- test$A18
te22 <- test$A22
train$A13 <- NULL
train$A18 <- NULL
train$A22 <- NULL
test$A13 <- NULL
test$A18 <- NULL
test$A22 <- NULL
#re-running the model after tuning the data
log_reg = glm(Target ~ ., data = train, family=binomial)
summary(log_reg)
# Prediction on train data
prob_train <- predict(log_reg, type = "response")
# Predicting on test data
prob_test <- predict(log_reg, test, type = "response")
#build ROC
library(ROCR)
pred <- prediction(prob_train, train$Target)
perf <- performance(pred, measure="tpr", x.measure="fpr")
#Plot the ROC curve using the extracted performance measures (TPR and FPR)
plot(perf, col=rainbow(10), colorize=T, print.cutoffs.at=seq(0,1,0.05))
perf_auc <- performance(pred, measure="auc")
auc <- perf_auc@y.values[[1]]
print(auc)
pred_class <- ifelse(prob_train > 0.1, 1, 0)
table(train$Target,pred_class)
pred_class <- ifelse(prob_train > 0.35, 1, 0)
table(train$Target,pred_class)
prob_val <- predict(log_reg, test, type = "response")
preds_val <- ifelse(prob_val > 0.35, 1, 0)
table(preds_val)
#Use vif to find any multi-collinearity
library(car)
log_reg_vif = vif(log_reg)
log_reg_vif
#dropping high vif for removing multi-collinearity
drops <- c("A5","A6","A7","A9","A10","A12")
train <- train[ , !(names(train) %in% drops)]
test <- test[ , !(names(train) %in% drops)]
#re-running the model after tuning the data
log_reg = glm(Target ~ ., data = train, family=binomial)
summary(log_reg)
rm(list = ls(all=TRUE))
#read the data
data <- read.csv('Data_20180408.csv',header=TRUE,na.strings = c(-99,"NA"))
#EDA
summary(data)
str(data)
dim(data)
#check NA's in data
sum(is.na(data))
#check NA's in each column
sapply(data, function(x)sum(is.na(x)))
#check unique values for each column
sapply(data, function(x) unique(x))
#change the variables to factors
data$A11 <- as.factor(data$A11)
data$A13 <- as.factor(data$A13)
data$A17 <- as.factor(data$A17)
data$A18 <- as.factor(data$A18)
data$A19 <- as.factor(data$A19)
data$A20 <- as.factor(data$A20)
data$A22 <- as.factor(data$A22)
data$Target <- as.factor(data$Target)
#split the data into train and test
set.seed(123)
rows=seq(1,nrow(data),1)
set.seed(123)
train_rows=sample(rows,round((70*nrow(data))/100))
train = data[train_rows,]
test = data[-train_rows,]
m1 <- mean(train$A2, na.rm = T)
m2 <- mean(train$A15 , na.rm = T)
m3 <- mean(train$A16 , na.rm = T)
train$A2[which(is.na(train$A2))]   <- m1
train$A15[which(is.na(train$A15))]   <- m2
train$A16[which(is.na(train$A16))]   <- m3
test$A2[which(is.na(test$A2))]   <- m1
test$A15[which(is.na(test$A15))]   <- m2
test$A16[which(is.na(test$A16))]   <- m3
#use SMOTE
library(DMwR)
train <- SMOTE(Target ~ ., train, perc.over = 200, perc.under=100)
summary(train$Target)
#drop some of the columns which have rare occurences
train$A11 <- NULL
train$A13 <- NULL
train$A18 <- NULL
train$A22 <- NULL
test$A11 <- NULL
test$A13 <- NULL
test$A18 <- NULL
test$A22 <- NULL
#train your model and then test it on unseen data
log_reg = glm(Target ~ ., data = train, family=binomial)
summary(log_reg)
# Prediction on train data
prob_train <- predict(log_reg, train, type = "response")
# Predicting on test data
prob_test <- predict(log_reg, test, type = "response")
#build AUC
library(ROCR)
pred <- prediction(prob_train, train$Target)
perf <- performance(pred, measure="tpr", x.measure="fpr")
#Plot the ROC curve using the extracted performance measures (TPR and FPR)
plot(perf, col=rainbow(10), colorize=T, print.cutoffs.at=seq(0,1,0.05))
perf_auc <- performance(pred, measure="auc")
auc <- perf_auc@y.values[[1]]
print(auc)
pred_class <- ifelse(prob_train > 0.6, 1, 0)
table(train$Target,pred_class)
prob_val <- predict(log_reg, test, type = "response")
preds_val <- ifelse(prob_val > 0.6, 1, 0)
table(preds_val)
conf_matrix <- table(test$Target, preds_val)
print(conf_matrix)
specificity <- conf_matrix[1, 1]/sum(conf_matrix[1, ])
sensitivity <- conf_matrix[2, 2]/sum(conf_matrix[2, ])
accuracy <- sum(diag(conf_matrix))/sum(conf_matrix)
pred_class <- ifelse(prob_train > 0.57, 1, 0)
table(train$Target,pred_class)
prob_val <- predict(log_reg, test, type = "response")
preds_val <- ifelse(prob_val > 0.57, 1, 0)
table(preds_val)
conf_matrix <- table(test$Target, preds_val)
print(conf_matrix)
specificity <- conf_matrix[1, 1]/sum(conf_matrix[1, ])
sensitivity <- conf_matrix[2, 2]/sum(conf_matrix[2, ])
pred_class <- ifelse(prob_train > 0.50, 1, 0)
table(train$Target,pred_class)
prob_val <- predict(log_reg, test, type = "response")
preds_val <- ifelse(prob_val > 0.50, 1, 0)
table(preds_val)
conf_matrix <- table(test$Target, preds_val)
print(conf_matrix)
specificity <- conf_matrix[1, 1]/sum(conf_matrix[1, ])
sensitivity <- conf_matrix[2, 2]/sum(conf_matrix[2, ])
rm(list = ls(all=TRUE))
#read the data
data <- read.csv('Data_20180408.csv',header=TRUE,na.strings = c(-99,"NA"))
#EDA
summary(data)
str(data)
dim(data)
#check NA's in data
sum(is.na(data))
#check NA's in each column
sapply(data, function(x)sum(is.na(x)))
#change the variables to factors
data$A11 <- as.factor(data$A11)
data$A13 <- as.factor(data$A13)
data$A17 <- as.factor(data$A17)
data$A18 <- as.factor(data$A18)
data$A19 <- as.factor(data$A19)
data$A20 <- as.factor(data$A20)
data$A22 <- as.factor(data$A22)
data$Target <- as.factor(data$Target)
#split the data into train and test
set.seed(123)
rows=seq(1,nrow(data),1)
set.seed(123)
train_rows=sample(rows,round((70*nrow(data))/100))
train = data[train_rows,]
test = data[-train_rows,]
m1 <- mean(train$A2, na.rm = T)
m2 <- mean(train$A15 , na.rm = T)
m3 <- mean(train$A16 , na.rm = T)
train$A2[which(is.na(train$A2))]   <- m1
train$A15[which(is.na(train$A15))]   <- m2
train$A16[which(is.na(train$A16))]   <- m3
test$A2[which(is.na(test$A2))]   <- m1
test$A15[which(is.na(test$A15))]   <- m2
test$A16[which(is.na(test$A16))]   <- m3
#use SMOTE
library(DMwR)
set.seed(123)
train <- SMOTE(Target ~ ., train, perc.over = 200, perc.under=100)
summary(train$Target)
#drop some of the columns which have rare occurences
train$A11 <- NULL
train$A13 <- NULL
train$A18 <- NULL
train$A22 <- NULL
test$A11 <- NULL
test$A13 <- NULL
test$A18 <- NULL
test$A22 <- NULL
#train your model and then test it on unseen data
log_reg = glm(Target ~ ., data = train, family=binomial)
summary(log_reg)
# Prediction on train data
prob_train <- predict(log_reg, train, type = "response")
# Predicting on test data
prob_test <- predict(log_reg, test, type = "response")
#build AUC
library(ROCR)
pred <- prediction(prob_train, train$Target)
perf <- performance(pred, measure="tpr", x.measure="fpr")
#Plot the ROC curve using the extracted performance measures (TPR and FPR)
plot(perf, col=rainbow(10), colorize=T, print.cutoffs.at=seq(0,1,0.05))
perf_auc <- performance(pred, measure="auc")
auc <- perf_auc@y.values[[1]]
print(auc)
#Plot the ROC curve using the extracted performance measures (TPR and FPR)
plot(perf, col=rainbow(10), colorize=T, print.cutoffs.at=seq(0,1,0.05))
pred_class <- ifelse(prob_train > 0.50, 1, 0)
table(train$Target,pred_class)
prob_val <- predict(log_reg, test, type = "response")
prob_val <- predict(log_reg, test, type = "response")
preds_val <- ifelse(prob_val > 0.50, 1, 0)
table(preds_val)
conf_matrix <- table(test$Target, preds_val)
print(conf_matrix)
specificity <- conf_matrix[1, 1]/sum(conf_matrix[1, ])
sensitivity <- conf_matrix[2, 2]/sum(conf_matrix[2, ])
accuracy <- sum(diag(conf_matrix))/sum(conf_matrix)
sensitivity
specificity
accuracy
